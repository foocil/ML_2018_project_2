{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def MF_SGD(data):\n",
    "    item_features, user_features, rmse = matrix_factorization_SGD(data, 0.008, 0.01, 0.01, 20, 30)\n",
    "    sparse_matrix = user_features.dot(item_features.T)\n",
    "    return sparse_matrix\n",
    "\n",
    "def compute_error_alternative(data, user_features, item_features, nz):\n",
    "    \"\"\"compute the loss (MSE) of the prediction of nonzero elements.\"\"\"\n",
    "    mse = 0\n",
    "    for row, col in nz:\n",
    "        item_info = item_features[col]\n",
    "        user_info = user_features[row]\n",
    "        mse += (data[row, col] - user_info.T.dot(item_info)) ** 2\n",
    "    return np.sqrt(1.0 * mse / len(nz))\n",
    "\n",
    "def parser(path_csv) :\n",
    "    maxUserId = 0\n",
    "    maxMovieId = 0\n",
    "    with open(path_csv, 'r') as csvfile:\n",
    "        linereader = csv.reader(csvfile, delimiter = ',')\n",
    "        next(linereader)\n",
    "        \n",
    "        for row in linereader:\n",
    "            rx, cy = row[0].split('_')\n",
    "            x, y = int(rx[1:]), int(cy[1:])\n",
    "            maxUserId = max(maxUserId, x)\n",
    "            maxMovieId = max(maxMovieId, y)\n",
    "    sparse_matrix = np.zeros((maxUserId,maxMovieId))\n",
    "    with open(path_csv, 'r') as csvfile:\n",
    "        linereader = csv.reader(csvfile, delimiter = ',')\n",
    "        next(linereader)\n",
    "        for row in linereader:\n",
    "            rx, cy = row[0].split('_')\n",
    "            x, y = int(rx[1:]), int(cy[1:])\n",
    "            sparse_matrix[x-1][y-1] = int(row[1])\n",
    "    return sparse_matrix\n",
    "\n",
    "def matrix_factorization_SGD(train, gamma, lambda_user, lambda_item, num_features, num_epochs):\n",
    "    \"\"\"matrix factorization by SGD.\"\"\"\n",
    "    errors = [0]\n",
    "    \n",
    "    # seed\n",
    "    np.random.seed(988)  \n",
    "    \n",
    "    # init matrices\n",
    "    num_users, num_items = train.shape \n",
    "    user_features = np.random.rand(num_users, num_features)\n",
    "    item_features = np.random.rand(num_items, num_features)\n",
    "    \n",
    "    # non-zero ratings indices \n",
    "    nz_row, nz_col = np.nonzero(train)\n",
    "    nz_train = list(zip(nz_row, nz_col))\n",
    "    print(\"Learning matrix factorization...\")\n",
    "    for it in range(num_epochs):        \n",
    "        # shuffle the training rating indices\n",
    "        np.random.shuffle(nz_train)\n",
    "\n",
    "        # decrease step size\n",
    "        gamma /= 1.2\n",
    "        \n",
    "        for x, y in nz_train:\n",
    "            item_info = item_features[y]\n",
    "            user_info = user_features[x]\n",
    "\n",
    "            # compute error : correct value - prediction\n",
    "            err = train[x, y] - user_info.dot(item_info.T)\n",
    "\n",
    "            # update latent factors\n",
    "            item_features[y] += gamma * (err * user_info - lambda_item * item_info)\n",
    "            user_features[x] += gamma * (err * item_info - lambda_user * user_info)\n",
    "\n",
    "        rmse = compute_error_alternative(train, user_features, item_features, nz_train)\n",
    "        print(\"iteration: {}, RMSE on training set: {}.\".format(it, rmse))\n",
    "        errors.append(rmse)\n",
    "\n",
    "    return item_features, user_features, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning matrix factorization...\n",
      "iteration: 0, RMSE on training set: 1.005979852470761.\n",
      "iteration: 1, RMSE on training set: 0.99562723154779.\n",
      "iteration: 2, RMSE on training set: 0.992188669307008.\n",
      "iteration: 3, RMSE on training set: 0.9896146826360068.\n",
      "iteration: 4, RMSE on training set: 0.9883877212533049.\n",
      "iteration: 5, RMSE on training set: 0.9868366331631652.\n",
      "iteration: 6, RMSE on training set: 0.9857337677964106.\n",
      "iteration: 7, RMSE on training set: 0.9847811306346373.\n",
      "iteration: 8, RMSE on training set: 0.9845721637083699.\n",
      "iteration: 9, RMSE on training set: 0.9837766810777655.\n",
      "iteration: 10, RMSE on training set: 0.9835880587912433.\n",
      "iteration: 11, RMSE on training set: 0.9829525727532762.\n",
      "iteration: 12, RMSE on training set: 0.9827335842837153.\n",
      "iteration: 13, RMSE on training set: 0.9824424619496241.\n",
      "iteration: 14, RMSE on training set: 0.9823578247036814.\n",
      "iteration: 15, RMSE on training set: 0.9821556064608257.\n",
      "iteration: 16, RMSE on training set: 0.9820439144588622.\n",
      "iteration: 17, RMSE on training set: 0.981990661714217.\n",
      "iteration: 18, RMSE on training set: 0.9818509013212792.\n",
      "iteration: 19, RMSE on training set: 0.981825556207817.\n",
      "iteration: 20, RMSE on training set: 0.9817973529915415.\n",
      "iteration: 21, RMSE on training set: 0.9817535818226246.\n",
      "iteration: 22, RMSE on training set: 0.9817251019102882.\n",
      "iteration: 23, RMSE on training set: 0.9817113028710085.\n",
      "iteration: 24, RMSE on training set: 0.9816983778903956.\n",
      "iteration: 25, RMSE on training set: 0.9816748541993032.\n",
      "iteration: 26, RMSE on training set: 0.9816564496282921.\n",
      "iteration: 27, RMSE on training set: 0.9816466951729671.\n",
      "iteration: 28, RMSE on training set: 0.9816396327507004.\n",
      "iteration: 29, RMSE on training set: 0.9816330547739894.\n"
     ]
    }
   ],
   "source": [
    "### path to the data\n",
    "path = \"../data/\"\n",
    "file_to_read = \"data_train.csv\"\n",
    "fileread = path + file_to_read\n",
    "fileread\n",
    "train = parser(fileread)\n",
    "i, u, err = matrix_factorization_SGD(train, 0.008, 0.01, 0.01, 20, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x2008ae3dba8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkpECQkREMvofbxJ/yaQhYQEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20082533cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "pd.Series(err[1:]).plot(logy=True)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Train Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization implemented with Surprise\n",
    "We used this to find the best parameters, since this library has a method cross-validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import surprise\n",
    "\n",
    "class MF_SGD(surprise.AlgoBase):\n",
    "    '''Prediction algorithm based on matrix factorization using SGD'''\n",
    "    \n",
    "    def __init__(self, gamma, num_features, lambda_user, lambda_item, num_epochs):\n",
    "        # initialize parameters\n",
    "        self.gamma = gamma\n",
    "        self.num_features = num_features\n",
    "        self.lambda_user = lambda_user\n",
    "        self.lambda_item = lambda_item\n",
    "        self.num_epochs = num_epochs\n",
    "\n",
    "        \n",
    "    def fit(self, trainset):\n",
    "        '''learn the vectors user_features and item_features with SGD'''\n",
    "    \n",
    "        print('Fitting data with SGD...')\n",
    "        \n",
    "        # randomly initialize the user and item factors.\n",
    "        user_features = np.random.normal(0, .1, (trainset.n_users, self.num_features))\n",
    "        item_features = np.random.normal(0, .1, (trainset.n_items, self.num_features))\n",
    "        \n",
    "        # SGD procedure\n",
    "        for _ in range(self.num_epochs):\n",
    "            for u, i, r_ui in trainset.all_ratings():\n",
    "                user_info = user_features[u]\n",
    "                item_info = item_features[i]\n",
    "                err = r_ui - np.dot(user_features[u], item_features[i])\n",
    "                # update vectors\n",
    "                user_features[u] += self.gamma * (err * item_info - self.lambda_user * user_info)\n",
    "                item_features[i] += self.gamma * (err * user_info - self.lambda_item * item_info)\n",
    "        \n",
    "        self.user_features, self.item_features = user_features, item_features\n",
    "        self.trainset = trainset\n",
    "\n",
    "    def estimate(self, u, i):\n",
    "        '''return the estimated rating of user u for item i.'''\n",
    "        # return scalar product between the vectors if user and item are known,\n",
    "        # else return the average of all ratings\n",
    "        if self.trainset.knows_user(u) and self.trainset.knows_item(i):\n",
    "            return np.dot(self.user_features[u], self.item_features[i])\n",
    "        else:\n",
    "            return self.trainset.global_mean\n",
    "\n",
    "def rmse_to_csv(rmse, params, name):\n",
    "    with open(name, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['Rmse','Parameters']\n",
    "        writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r1, r2 in zip(rmse, params):\n",
    "            writer.writerow({'Rmse':r1, 'Parameters':r2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_new_csv(\"../data/data_train.csv\")\n",
    "reader = surprise.Reader(line_format=\"user item rating\", sep=',', rating_scale=(1, 5))\n",
    "data = surprise.Dataset.load_from_file('new_data.csv', reader=reader)\n",
    "rmses = []\n",
    "params = []       \n",
    "#try for some combination of parameters\n",
    "for gamma in [0.004, 0.006, 0.008, 0.1]:\n",
    "    for lu in [0.01, 0.03, 0.05, 0.07]:\n",
    "        for li in [0.01, 0.03, 0.05, 0.07]:\n",
    "            params.append((gamma, lu, li))           \n",
    "for (g, lu, li) in params:\n",
    "    algo = MF_SGD(gamma=g, num_features=20, lambda_user=lu, lambda_item=li, num_epochs=10)\n",
    "    rmse = surprise.model_selection.cross_validate(algo, data, measures=['RMSE'])\n",
    "    rmses.append(rmse)\n",
    "rmse_to_csv(rmses, params, \"error_sur1.csv\")\n",
    "print(\"fin\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
