{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_MF(train, num_features):\n",
    "    \"\"\"init the parameter for matrix factorization.\"\"\"\n",
    "        \n",
    "    num_item, num_user = train.shape\n",
    "\n",
    "    user_features = np.random.rand(num_features, num_user)\n",
    "    item_features = np.random.rand(num_features, num_item)\n",
    "\n",
    "    # start by item features.\n",
    "    item_nnz = train.getnnz(axis=1)\n",
    "    item_sum = train.sum(axis=1)\n",
    "\n",
    "    for ind in range(num_item):\n",
    "        item_features[0, ind] = item_sum[ind, 0] / item_nnz[ind]\n",
    "    return user_features, item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(data, user_features, item_features, nz):\n",
    "    \"\"\"compute the loss (MSE) of the prediction of nonzero elements.\"\"\"\n",
    "    mse = 0\n",
    "    for row, col in nz:\n",
    "        item_info = item_features[:, row]\n",
    "        user_info = user_features[:, col]\n",
    "        mse += (data[row, col] - user_info.T.dot(item_info)) ** 2\n",
    "    return np.sqrt(1.0 * mse / len(nz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_user_feature(\n",
    "        train, item_features, lambda_user,\n",
    "        nnz_items_per_user, nz_user_itemindices):\n",
    "    \"\"\"update user feature matrix.\"\"\"\n",
    "    \"\"\"the best lambda is assumed to be nnz_items_per_user[user] * lambda_user\"\"\"\n",
    "    num_user = nnz_items_per_user.shape[0]\n",
    "    num_feature = item_features.shape[0]\n",
    "    lambda_I = lambda_user * sp.eye(num_feature)\n",
    "    updated_user_features = np.zeros((num_feature, num_user))\n",
    "\n",
    "    for user, items in nz_user_itemindices:\n",
    "        # extract the columns corresponding to the prediction for given item\n",
    "        M = item_features[:, items]\n",
    "        \n",
    "        # update column row of user features\n",
    "        V = M @ train[items, user]\n",
    "        A = M @ M.T + nnz_items_per_user[user] * lambda_I\n",
    "        X = np.linalg.solve(A, V)\n",
    "        updated_user_features[:, user] = np.copy(X.T)\n",
    "    return updated_user_features\n",
    "\n",
    "def update_item_feature(\n",
    "        train, user_features, lambda_item,\n",
    "        nnz_users_per_item, nz_item_userindices):\n",
    "    \"\"\"update item feature matrix.\"\"\"\n",
    "    \"\"\"the best lambda is assumed to be nnz_items_per_item[item] * lambda_item\"\"\"\n",
    "    num_item = nnz_users_per_item.shape[0]\n",
    "    num_feature = user_features.shape[0]\n",
    "    lambda_I = lambda_item * sp.eye(num_feature)\n",
    "    updated_item_features = np.zeros((num_feature, num_item))\n",
    "\n",
    "    for item, users in nz_item_userindices:\n",
    "        # extract the columns corresponding to the prediction for given user\n",
    "        M = user_features[:, users]\n",
    "        V = M @ train[item, users].T\n",
    "        A = M @ M.T + nnz_users_per_item[item] * lambda_I\n",
    "        X = np.linalg.solve(A, V)\n",
    "        updated_item_features[:, item] = np.copy(X.T)\n",
    "    return updated_item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "def group_by(data, index):\n",
    "    \"\"\"group list of list by a specific index.\"\"\"\n",
    "    sorted_data = sorted(data, key=lambda x: x[index])\n",
    "    groupby_data = groupby(sorted_data, lambda x: x[index])\n",
    "    return groupby_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index_groups(train):\n",
    "    \"\"\"build groups for nnz rows and cols.\"\"\"\n",
    "    nz_row, nz_col = train.nonzero()\n",
    "    nz_train = list(zip(nz_row, nz_col))\n",
    "\n",
    "    grouped_nz_train_byrow = group_by(nz_train, index=0)\n",
    "    nz_row_colindices = [(g, np.array([v[1] for v in value]))\n",
    "                         for g, value in grouped_nz_train_byrow]\n",
    "\n",
    "    grouped_nz_train_bycol = group_by(nz_train, index=1)\n",
    "    nz_col_rowindices = [(g, np.array([v[0] for v in value]))\n",
    "                         for g, value in grouped_nz_train_bycol]\n",
    "    return nz_train, nz_row_colindices, nz_col_rowindices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ALS(train):\n",
    "    \"\"\"Alternating Least Squares (ALS) algorithm.\"\"\"\n",
    "    # define parameters\n",
    "    num_features = 20   # K in the lecture notes\n",
    "    lambda_user = 0.08\n",
    "    lambda_item = 0.08\n",
    "    stop_criterion = 1e-4\n",
    "    change = 1\n",
    "    error_list = [0, 0]\n",
    "    train = sp.csr_matrix(train)\n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init ALS\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # get the number of non-zero ratings for each user and item\n",
    "    nnz_items_per_user, nnz_users_per_item = train.getnnz(axis=0), train.getnnz(axis=1)\n",
    "    \n",
    "    # group the indices by row or column index\n",
    "    nz_train, nz_item_userindices, nz_user_itemindices = build_index_groups(train)\n",
    "\n",
    "    # run ALS\n",
    "    print(\"\\nstart the ALS algorithm...\")\n",
    "    while change > stop_criterion:\n",
    "        # update user feature & item feature\n",
    "        user_features = update_user_feature(\n",
    "            train, item_features, lambda_user,\n",
    "            nnz_items_per_user, nz_user_itemindices)\n",
    "        item_features = update_item_feature(\n",
    "            train, user_features, lambda_item,\n",
    "            nnz_users_per_item, nz_item_userindices)\n",
    "\n",
    "        error = compute_error(train, user_features, item_features, nz_train)\n",
    "        print(\"RMSE on training set: {}.\".format(error))\n",
    "        error_list.append(error)\n",
    "        change = np.fabs(error_list[-1] - error_list[-2])\n",
    "        print(change)\n",
    "    \n",
    "    # evaluate the test error\n",
    "    rmse = compute_error(train, user_features, item_features, nz_train)\n",
    "    print(\"Train RMSE after running ALS: {v}.\".format(v=rmse))\n",
    "    \n",
    "    return user_features.T @ item_features, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(path_csv) :\n",
    "    maxUserId = 0\n",
    "    maxMovieId = 0\n",
    "    with open(path_csv, 'r') as csvfile:\n",
    "        linereader = csv.reader(csvfile, delimiter = ',')\n",
    "        next(linereader)\n",
    "        \n",
    "        for row in linereader:\n",
    "            rx, cy = row[0].split('_')\n",
    "            x, y = int(rx[1:]), int(cy[1:])\n",
    "            maxUserId = max(maxUserId, x)\n",
    "            maxMovieId = max(maxMovieId, y)\n",
    "    sparse_matrix = np.zeros((maxUserId,maxMovieId))\n",
    "    with open(path_csv, 'r') as csvfile:\n",
    "        linereader = csv.reader(csvfile, delimiter = ',')\n",
    "        next(linereader)\n",
    "        for row in linereader:\n",
    "            rx, cy = row[0].split('_')\n",
    "            x, y = int(rx[1:]), int(cy[1:])\n",
    "            sparse_matrix[x-1][y-1] = int(row[1])\n",
    "    return sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(ratings, num_items_per_user, num_users_per_item,\n",
    "               min_num_ratings, p_test=0.1):\n",
    "    \"\"\"split the ratings to training data and test data.\n",
    "    Args:\n",
    "        min_num_ratings: \n",
    "            all users and items we keep must have at least min_num_ratings per user and per item. \n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "    \n",
    "    # select user and item based on the condition.\n",
    "    valid_users = np.where(num_items_per_user >= min_num_ratings)[0]\n",
    "    valid_items = np.where(num_users_per_item >= min_num_ratings)[0]\n",
    "    valid_ratings = ratings[valid_items, :][: , valid_users]  \n",
    "    \n",
    "    # init\n",
    "    num_rows, num_cols = valid_ratings.shape\n",
    "    train = sp.lil_matrix((num_rows, num_cols))\n",
    "    test = sp.lil_matrix((num_rows, num_cols))\n",
    "    \n",
    "    print(\"the shape of original ratings. (# of row, # of col): {}\".format(\n",
    "        ratings.shape))\n",
    "    print(\"the shape of valid ratings. (# of row, # of col): {}\".format(\n",
    "        (num_rows, num_cols)))\n",
    "\n",
    "    nz_items, nz_users = valid_ratings.nonzero()\n",
    "    \n",
    "    # split the data\n",
    "    for user in set(nz_users):\n",
    "        # randomly select a subset of ratings\n",
    "        row, col = valid_ratings[:, user].nonzero()\n",
    "        selects = np.random.choice(row, size=int(len(row) * p_test))\n",
    "        residual = list(set(row) - set(selects))\n",
    "\n",
    "        # add to train set\n",
    "        train[residual, user] = valid_ratings[residual, user]\n",
    "\n",
    "        # add to test set\n",
    "        test[selects, user] = valid_ratings[selects, user]\n",
    "\n",
    "    print(\"Total number of nonzero elements in origial data:{v}\".format(v=ratings.nnz))\n",
    "    print(\"Total number of nonzero elements in train data:{v}\".format(v=train.nnz))\n",
    "    print(\"Total number of nonzero elements in test data:{v}\".format(v=test.nnz))\n",
    "    return valid_ratings, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverseParser(sparse_matrix, pathToSample, pathToFinal):\n",
    "    ## given the sample submission, it will update the value of each line.\n",
    "    \n",
    "    with open(pathToSample, 'r') as csvfile, open(pathToFinal, 'w', newline='') as csvFinal:\n",
    "        linereader = csv.reader(csvfile, delimiter =',')\n",
    "        linewriter = csv.writer(csvFinal, delimiter =',')\n",
    "        linewriter.writerow([\"Id\",\"Prediction\"])\n",
    "        next(linereader)\n",
    "        for row in linereader:\n",
    "            rx, cy = row[0].split('_')\n",
    "            x, y = int(rx[1:]), int(cy[1:])\n",
    "            rx_cy = \"r\"+str(x)+\"_c\"+str(y)\n",
    "            if(sparse_matrix[x-1][y-1] < 1): sparse_matrix[x-1][y-1] = 1\n",
    "            if(sparse_matrix[x-1][y-1] > 5): sparse_matrix[x-1][y-1] = 5\n",
    "            linewriter.writerow([rx_cy, int(round(sparse_matrix[x-1][y-1]))])\n",
    "    print(\"Writing is done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### path to the data\n",
    "path = \"../data/\"\n",
    "file_to_read = \"data_train.csv\"\n",
    "fileread = path + file_to_read\n",
    "fileread\n",
    "train = parser(fileread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start the ALS algorithm...\n",
      "RMSE on training set: 1.048153205690883.\n",
      "1.048153205690883\n",
      "RMSE on training set: 1.014050177944071.\n",
      "0.034103027746812176\n",
      "RMSE on training set: 0.9768601371898459.\n",
      "0.03719004075422505\n",
      "RMSE on training set: 0.9503021006311955.\n",
      "0.02655803655865041\n",
      "RMSE on training set: 0.9349440324499755.\n",
      "0.015358068181219986\n",
      "RMSE on training set: 0.9259827076442098.\n",
      "0.008961324805765725\n",
      "RMSE on training set: 0.9202205977082003.\n",
      "0.005762109936009452\n",
      "RMSE on training set: 0.9161983467037053.\n",
      "0.004022251004495048\n",
      "RMSE on training set: 0.9132391529908327.\n",
      "0.0029591937128725654\n",
      "RMSE on training set: 0.9109832260336556.\n",
      "0.0022559269571771345\n",
      "RMSE on training set: 0.9092165084864704.\n",
      "0.0017667175471851593\n",
      "RMSE on training set: 0.9078025825487778.\n",
      "0.0014139259376926283\n",
      "RMSE on training set: 0.9066505202210835.\n",
      "0.0011520623276942699\n",
      "RMSE on training set: 0.9056976118169013.\n",
      "0.0009529084041821623\n",
      "RMSE on training set: 0.9048993572124056.\n",
      "0.000798254604495785\n",
      "RMSE on training set: 0.9042233795795613.\n",
      "0.0006759776328442157\n",
      "RMSE on training set: 0.9036455923644462.\n",
      "0.0005777872151151442\n",
      "RMSE on training set: 0.9031477173080167.\n",
      "0.0004978750564295087\n",
      "RMSE on training set: 0.9027156385258884.\n",
      "0.00043207878212825346\n",
      "RMSE on training set: 0.9023382865648899.\n",
      "0.00037735196099852875\n",
      "RMSE on training set: 0.902006865204766.\n",
      "0.0003314213601238736\n",
      "RMSE on training set: 0.9017143041164498.\n",
      "0.0002925610883162122\n",
      "RMSE on training set: 0.9014548632276742.\n",
      "0.00025944088877560834\n",
      "RMSE on training set: 0.9012238410676461.\n",
      "0.00023102216002812703\n",
      "RMSE on training set: 0.9010173558971505.\n",
      "0.00020648517049559612\n",
      "RMSE on training set: 0.9008321788990398.\n",
      "0.0001851769981107143\n",
      "RMSE on training set: 0.9006656053959452.\n",
      "0.0001665735030945692\n",
      "RMSE on training set: 0.9005153543932779.\n",
      "0.00015025100266730096\n",
      "RMSE on training set: 0.9003794895802142.\n",
      "0.000135864813063713\n",
      "RMSE on training set: 0.9002563568119605.\n",
      "0.00012313276825370867\n",
      "RMSE on training set: 0.900144534381065.\n",
      "0.00011182243089546962\n",
      "RMSE on training set: 0.9000427932834756.\n",
      "0.00010174109758942507\n",
      "RMSE on training set: 0.8999500653310071.\n",
      "9.272795246850762e-05\n",
      "Train RMSE after running ALS: 0.8999500653310071.\n"
     ]
    }
   ],
   "source": [
    "predicted, rmse = ALS(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Train error')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [1.048153205690883, 1.014050177944071, 0.9768601371898459, 0.9349440324499755, 0.9259827076442098, 0.9202205977082003, \n",
    "        0.9161983467037053, 0.9132391529908327, 0.9109832260336556, 0.9092165084864704,\n",
    "        0.9078025825487778, 0.9066505202210835, 0.9056976118169013, 0.9048993572124056,\n",
    "        0.9042233795795613, 0.9036455923644462, 0.9031477173080167, 0.9027156385258884,\n",
    "        0.9023382865648899, 0.902006865204766, 0.9017143041164498, 0.9014548632276742,\n",
    "        0.9012238410676461, 0.9010173558971505, 0.9008321788990398, 0.9006656053959452,\n",
    "        0.9005153543932779, 0.9003794895802142, 0.9002563568119605, 0.900144534381065,\n",
    "        0.9000427932834756, 0.8999500653310071]\n",
    "\n",
    "pd.Series(data).plot(logy=True)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Train error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing is done\n"
     ]
    }
   ],
   "source": [
    "pathout = \"../reports/\"\n",
    "filename = \"../data/sample_submission.csv\"\n",
    "totalFinal = path + \"out\"\n",
    "totalFinal = totalFinal + \".csv\"\n",
    "reverseParser(predicted.T, filename, totalFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'path = \"../data/\"\\nfilename = \"sample_submission.csv\"\\ntotalSample = path + filename\\ntotalFinal = path + \"outFor\"\\ntrain = sp.csr_matrix(train)\\nfor i in range(1,10):\\n    predicted = ALS(train, (1.0/10.0**i))\\n    totalFinal = totalFinal + str(i) + \".csv\"\\n    reverseParser(predicted.T, totalSample, totalFinal)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''path = \"../data/\"\n",
    "filename = \"sample_submission.csv\"\n",
    "totalSample = path + filename\n",
    "totalFinal = path + \"outFor\"\n",
    "train = sp.csr_matrix(train)\n",
    "for i in range(1,10):\n",
    "    predicted = ALS(train, (1.0/10.0**i))\n",
    "    totalFinal = totalFinal + str(i) + \".csv\"\n",
    "    reverseParser(predicted.T, totalSample, totalFinal)'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
